<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据仓库 on @Qian Sun</title>
    <link>https://dcoliversun.github.io/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</link>
    <description>Recent content in 数据仓库 on @Qian Sun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>cn</language>
    <lastBuildDate>Wed, 06 Jan 2021 20:42:47 +0800</lastBuildDate><atom:link href="https://dcoliversun.github.io/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lakehouse：统一数据仓库和高级分析的开放数据平台</title>
      <link>https://dcoliversun.github.io/2021/lakehouse/</link>
      <pubDate>Wed, 06 Jan 2021 20:42:47 +0800</pubDate>
      
      <guid>https://dcoliversun.github.io/2021/lakehouse/</guid>
      <description>Lakehouse架构逐渐在工业界铺开，第三代数据分析平台进入大众视野！
原文在这里👉Lakehouse
 摘要 论文认为数据仓库架构在未来一段时间内会逐渐消亡，取而代之的是一种新型Lakehouse架构，该架构具有如下特特性：
 基于开放的数据格式，例如Apache Parquet 完全支持机器学习和数据科学 提供卓越的性能  Lakehouse解决数据仓库面临的主要挑战——数据陈旧、可靠性不高、总成本大、数据格式受限、场景支持受限。论文下面会讨论Lakehouse架构为何取得工业界青睐以及如何影响数据管理。
数据分析平台发展 数据仓库将业务数据库的数据收集到集中式仓库，帮助企业领导分析数据，之后被用于决策支持和商业智能（BI）。数据仓库使用写模式（schema-on-write）写入数据，优化下游BI消费的数据模型。这就是第一代数据分析平台。
后来第一代平台开始面临诸多挑战。首先是计算与存储耦合使得扩容成本增加，这迫使企业支付用户负载和数据管理峰值的成本，这个成本随着数据规模增加而迅速增加。其次，越来越多的数据集是非结构化的，例如视频、音频和文本文档，而数据仓库无法存储、查询这类数据。
为了解决这些问题，第二代数据分析平台将所有原始数据导入数据湖：具有文件API的低成本存储系统，该系统可存储开放数据格式，例如Apache Parquet和ORC。这个方法源起于Apache Hadoop，基于HDFS实现低成本存储。数据湖是一种读模式（schema-on-read）架构，可以灵活、低成本地存储数据，也解决了数据质量和下游管理的问题。该架构中的一小部分数据在进行ETL后注入下游数据仓库，再进行决策支持和BI分析。开放数据格式使得绝大多数分析引擎可以直接访问数据湖数据。
2015年起，云数据湖（S3、ADLS、GCS、OSS等）开始取代HDFS，它们具有超强的持久性、冗余可靠、超低存储成本。云上架构与第二代平台架构相同，例如Redshift、Snowflake。数据湖+数据仓库两层架构当今在工业界中占主导地位。
如今，这种架构面临新的挑战。尽管存储和计算的分离使得云数据湖+数据仓库架构的成本降低，可增加了用户的使用成本。在第一代平台中，所有业务数据库中的数据经过ETL后直接注入数据仓库。第二代平台却在中间引进了数据湖，增加了额外的复杂性、延迟与故障率。同时，数据湖+数据仓库二层架构不能很好支持机器学习之类的高级分析。具体来看，可以归纳为四个问题：
 可靠性。保持数据湖与数据仓库的一致性是成本高昂且困难的事情。需要对两个系统之间的ETL作业进行仔细设计，如此方可进行高性能决策支持与BI分析。每个ETL步骤还有发生故障或引入错误的风险，例如由于数据湖和数据仓库引擎之间的细微差别而导致数据质量降低的风险。 数据陈旧。数据仓库数据的时效性低于数据湖数据，新数据的加载通常要花费几天。与第一代分析系统相比，这是个倒退，第一代分析系统可以直接查询新的业务数据。根据Dimensional Research与Fivetran调查，86%的分析使用过时数据，62%的报告每月需要等待几次引擎资源。 对高级分析支持有限。企业希望使用数据进行预测，例如“我应该为哪些顾客提供折扣？”。 尽管许多研究关注机器学习与数据管理结合，但主流机器学习系统没有一个可以工作在数据仓库上，包括TensorFlow、PyTorch和XGBoost。与BI查询少量数据不同，这些机器学习系统需要使用复杂的No-SQL代码处理大型数据集，但通过ODBC/JDBC读取数据效率很低，并且无法直接访问数据仓库内部专有格式的数据。对于这类场景，数据仓库供应商建议导出数据为文件，但这增加了复杂性和滞后性，因为添加了第三个ETL。或者，用户可以在支持开发格式的数据湖上运行这些系统，这会抛弃数据仓库丰富的数据管理功能，例如ACID事务、数据版本控制与索引。 总成本。除了支付ETL作业费用外，用户还得为复制到数据仓库的数据支付两倍的存储成本，而数据仓库使用的内部格式额外引入数据或工作负载迁移到其他系统的成本。  一种被广泛采用的解决方案是不使用数据湖 ，将所有数据存储在计算、存储分离的数据仓库中。论文认为这种方案可行性有限，因为不支持视频、音频和文本数据或从机器学习和数据科学工作负载中直接访问。
论文作者提出了一个问题：是否可以将基于开放数据格式（Parquet与ORC）的数据湖转为一个高性能系统，该系统既拥有数据仓库强大的性能、管理功能，又可直接、快速访问高级分析工作负载？随着越来越多的业务应用开始依赖运营数据和高级分析，Lakehouse架构可以消除数据仓库的上述挑战。
作者相信Lakehouse的时机已经到来！
Lakehouse可解决以下问题：
 数据湖上可靠的数据管理：Lakehouse需要存储原始数据，同时支持ETL/ELT流程来提高数据分析质量。传统数据湖将半结构化数据以“一堆文件”形式进行管理，很难提供一些简化ETL/ELT的关键管理功能，例如事务、回滚、零拷贝。然而，以Delta Lake和Apache Iceberg为代表的新型数据湖框架提供了数据湖的事物视图，并提供了管理功能，减少ETL步骤，并且分析人员可以高效查询原始数据表，这与第一代分析平台很像。 支持机器学习和数据科学：机器学习系统支持直接读取数据湖数据格式，很多系统采用DataFrames作为操作数据的抽象，而声明式DataFrame APIs可以为机器学习工作负载中的数据访问进行查询优化，可以让机器学习工作负载直接享受Lakehouse的优化点。 SQL性能：Lakehouse需要在海量Parquet/ORC数据集上提供很好的SQL性能，相比之下经典数据仓库对SQL优化更彻底。尽管如此，论文提出需要维护Parquet/ORC数据集的辅助数据，在现有格式内优化数据布局以实现更好的性能。  出发点：数据仓库的挑战 当前工业界对数据仓库不是很满意。首先是数据质量和可靠性不高，维护数据流分析的准确性是一件很困难的工作。其次，越来越多的商业分析需要最新的数据，但数据仓库不可避免地引入数据滞后性。第三，如今的非结构化数据比重大幅增加，但数据仓库并不能提供很好的非结构化数据分析。最后，现在工业界部署的机器学习与数据科学应用无法从数据仓库和数据湖中得到很好的支持。
当前工业界对数据湖+数据仓库的两层架构并不满意。首先是几乎所有的数据仓库近期都增加了对Parquet和ORC格式的外部表支持，允许数据仓库用户可以从相同的SQL引擎查询数据湖表，但这没有降低数据湖管理难度，也没有消除数据仓库ETL复杂度、滞后性和高级分析挑战。实际上，这些支持的性能通常较差，因为SQL引擎主要针对其内部数据格式进行了优化。其次，直接针对数据湖存储的SQL引擎也有广泛产品，例如Spark SQL、Presto、Hive和AWS Athena。然而，这些引擎不能解决数据湖所有问题，也不能取代数据仓库，数据湖仍然缺少包括ACID事务的基础管理功能和有效访问方法，例如与数据仓库性能匹配的索引。
Lakehouse架构 论文为Lakehouse提出一个定义：基于低成本、直接访问存储的数据管理系统，该系统具有传统分析型DBMS管理和性能，例如ACID事务、数据版本管理、数据审计、索引、缓存和查询优化。可以看出，Lakehouse结合了数据湖和数据仓库的核心优势。问题的关键在于是否可以有效结合这些优势，特别是Lakehouse对直接访问的支持意味着其放弃了部分数据独立性。
Lakehouse天然适合计算、存储分离的云环境：不同的计算应用程序按需分配在完全独立的计算节点（例如ML的GPU集群），同时直接访问相同的存储数据，但也可以在本地存储系统（如HDFS）上实现Lakehouse。
实现Lakehouse系统 实现Lakehouse的第一个关键思想是使用标准文件格式（如Parquet）将数据存储在低成本的对象存储（如Amazon S3、OSS）中，并在对象存储上实现元数据层，其定义了哪些对象是表版本一部分。这使系统可以在元数据层实现如ACID事务处理或版本控制之类的管理功能，同时将大量数据保存在低成本对象存储中，并允许客户端使用使用标准文件格式直接从该存储中读取对象。
尽管元数据层增加了管理功能，但不足以实现良好的SQL性能。数据仓库使用多种技术获得性能提升，比如将热数据存储在SSD等高速设备、维护统计信息、构建有效的访问方法（如索引）以及优化数据格式和计算引擎。基于现有存储格式的Lakehouse无法变更格式，但是也可以实现保持数据文件不变情况下的其他优化，包括缓存、辅助数据结构（例如索引和统计信息）和数据布局优化。
最终，Lakehouse既可以加快高级分析负载，又可以为其提供更好的数据管理功能。许多机器学习库（如Tensorflow和Spark MLlib）已经可以读取数据湖文件格式（如Parquet）。因此将它们与Lakeehouse集成最简单方法是查询元数据层，查询哪些Parquet文件属于表，然后将它们传递给机器学习库。这些系统支持DataFrame API，以便进行更好的优化。R与Pandas推广了DataFrames，为用户提供包含多种操作符的表抽象，其中大多数映射到关系代数。Spark SQL等系统通过惰性计算转换与传递结果操作步骤到优化器实现该API声明式。因此，这些API可利用Lakehouse新优化特性实现机器学习加速，例如缓存和辅助数据。
用于数据管理的元数据层 Lakehouses的第一个组件是元数据层，其可以实现ACID事务和其他管理功能。诸如S3或HDFS之类的数据湖存储系统仅提供了低级的对象存储或文件系统接口，在这些接口中，即使是简单的操作（如更新跨多个文件的表）也不是原子的，这个问题使得一些组织开始设计更丰富的数据管理层，从Apache Hive ACID开始，其使用OLTP DBMS跟踪给定表版本中哪些数据文件是Hive表的一部分，并允许操作以事务方式更新此集合。近年来一些新系统提供了更多功能和改进的可伸缩性，如2016年Databricks开发的Delta Lake，其将有关哪些对象是表中一部分的信息存储在数据湖中，作为Parquet格式的事务日志，使其能够扩展到每张表数十亿个对象；Netflix的Apache Iceberg也使用类似的设计，并支持Parquet和ORC存储；Apache Hudi始于Uber也类似，尽管它不支持并发写入（正在支持中），该系统侧重于简化流式数据入数据湖。
这些系统的经验表明它们可以提供与原始Parquet/ORC数据湖类似或更好的性能，同时还增加了非常有用的管理功能，例如事务处理，零拷贝和回滚。
元数据层对数据质量非常重要，例如可以对Schema进行校验，使其不破坏数据质量。
另外元数据层可以实现诸如访问控制和审核日志记录之类的治理功能，例如元数据层可以在授予客户端凭据以从云对象存储读取表中的原始数据之前，检查是否允许客户端访问表，并且记录所有访问行为。
未来方向和替代设计。由于数据湖的元数据层非常新，因此存在许多悬而未决的问题和替代设计。例如Delta Lake设计为将事务日志存储在它运行的同一对象存储中（例如S3）以简化管理（消除了运行单独存储系统的需要）并提供高可用性和高读取带宽，但对象存储的高延迟限制了它可以支持的每秒事务处理速率，在某些情况下将元数据使用更快的存储系统的设计可能更可取。同样Delta Lake，Iceberg和Hudi仅支持单表事务，但也可以扩展以支持跨表事务，优化事务日志的格式和管理对象的大小也是未解决的问题。</description>
    </item>
    
  </channel>
</rss>
